---
import Layout from "../layouts/Layout.astro";
---

<Layout 
  title="What is AI Safety?"
  description="Understand AI safety: what it is, why it matters, and how Durham AISI helps students and academics work on alignment, governance, and safety."
>
  <script
    type="application/ld+json"
    slot="head"
    set:html={JSON.stringify({
      "@context": "https://schema.org",
      "@type": "FAQPage",
      "mainEntity": [
        {
          "@type": "Question",
          "name": "What is AI safety?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "AI Safety is the field focused on ensuring that artificial intelligence systems are safe, beneficial, and aligned with human values as they become increasingly capable."
          }
        },
        {
          "@type": "Question",
          "name": "Why is AI safety important?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "As capabilities accelerate toward frontier and potentially superhuman systems, small design mistakes or misaligned objectives can scale into large harms. AI safety reduces risks of unintended behavior, misuse, and systemic failures, protecting people and institutions while enabling responsible progress and the upside of powerful AI."
          }
        },
        {
          "@type": "Question",
          "name": "How can I get involved in AI safety at Durham?",
          "acceptedAnswer": {
            "@type": "Answer",
            "text": "Start by attending our intro seminars, join an in‑depth reading group, and talk to us about research or policy projects. We support dissertation topics and applications to fellowships and funding from external orgs. See the Programs and Get Involved pages for upcoming activities and ways to contribute, regardless of background."
          }
        }
      ]
    })}
  />

  <section class="section section-neutral">
    <div class="container text-center">
      <h1 class="text-4xl md:text-5xl font-bold mb-4">AI Safety and Why It Matters</h1>
      <div class="w-24 h-1 bg-gradient-to-r from-bright-purple to-light-purple mx-auto rounded-full"></div>
    </div>
  </section>

  {/* The Foundation */}
  <section class="section section-neutral">
    <div class="container">
      <div class="text-center mb-16">
        <h3 class="text-3xl md:text-4xl font-bold mb-6">What is AI Safety?</h3>
        <div class="section-divider"></div>
      </div>

      <div class="max-w-4xl mx-auto">
        <div class="info-card p-8 mb-8">
          <p class="text-xl md:text-2xl leading-relaxed text-center mb-6">
            AI Safety is the field focused on ensuring that artificial intelligence systems are
            <span class="gradient-text font-semibold"> safe, beneficial, and aligned with human values</span>
            as they become increasingly capable.
          </p>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-3 gap-8">
          <div class="info-card p-6 card-hover text-center">
            <div class="w-16 h-16 bg-gradient-to-br from-teal to-emerald rounded-xl flex items-center justify-center mx-auto mb-4">
              <i class="fas fa-shield-alt text-2xl text-white" aria-hidden="true"></i>
            </div>
            <h4 class="text-xl font-bold mb-4">Safety</h4>
            <p class="text-sm leading-relaxed">
              Ensuring AI systems operate reliably and don't cause unintended harm to humans or society.
            </p>
          </div>

          <div class="info-card p-6 card-hover text-center">
            <div class="w-16 h-16 bg-gradient-to-br from-emerald to-sage rounded-xl flex items-center justify-center mx-auto mb-4">
              <i class="fas fa-heart text-2xl text-white" aria-hidden="true"></i>
            </div>
            <h4 class="text-xl font-bold mb-4">Beneficial</h4>
            <p class="text-sm leading-relaxed">
              Designing AI to actively promote human welfare and contribute positively to society.
            </p>
          </div>

          <div class="info-card p-6 card-hover text-center">
            <div class="w-16 h-16 bg-gradient-to-br from-ocean-blue to-warm-blue rounded-xl flex items-center justify-center mx-auto mb-4">
              <i class="fas fa-balance-scale text-2xl text-white" aria-hidden="true"></i>
            </div>
            <h4 class="text-xl font-bold mb-4">Aligned</h4>
            <p class="text-sm leading-relaxed">
              Ensuring AI systems understand and pursue goals that align with human values and intentions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  {/* Why It Matters & Getting Started */}
  <section class="section section-neutral">
    <div class="container">
      {/* Why AI Safety Matters */}
      <div class="text-center mb-16">
        <h3 class="text-3xl md:text-4xl font-bold mb-6">Why AI Safety Matters</h3>
        <div class="section-divider"></div>
      </div>
      <div class="max-w-6xl mx-auto mb-20">
        <div class="space-y-12">
          <div class="timeline-item">
            <div class="info-card p-8">
              <h4 class="text-2xl font-bold mb-4" style="color: var(--color-bright-purple)">1. AI systems far smarter than us may be created soon.</h4>
              <p class="text-slate-600 leading-relaxed mb-6">
                AI is advancing fast, and this progress may result in human-level AI. But human-level is not the limit, and shortly after, there's a good chance we'd see superintelligent AI.
              </p>

              <div class="mb-6">
                <iframe width="100%" height="315" src="https://www.youtube.com/embed/fa8k8IQ1_X0" title="Superintelligence - AI Safety Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen class="rounded-lg"></iframe>
              </div>

              <div class="space-y-3 mb-4">
                <div class="flex items-center">
                  <i class="fas fa-chart-line mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Rapid advances in AI capabilities</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-rocket mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Potential for explosive intelligence growth</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-clock mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Timeline uncertainty but potentially soon</span>
                </div>
              </div>

              <a href="https://aisafety.info/questions/NM37/1%3A%20AI%20is%20advancing%20fast" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-purple-700 hover:text-purple-500 transition-colors">
                <span class="underline">Learn more about AI advancement</span>
                <i class="fas fa-external-link-alt ml-2" aria-hidden="true"></i>
              </a>
            </div>
          </div>

          <div class="timeline-item">
            <div class="info-card p-8">
              <h4 class="text-2xl font-bold mb-4" style="color: var(--color-light-purple)">2. These systems may end up opposed to us.</h4>
              <p class="text-slate-600 leading-relaxed mb-6">
                AI systems may pursue their own goals, those goals may not match ours, and that may bring them into conflict with us.
              </p>

              <div class="space-y-3 mb-4">
                <div class="flex items-center">
                  <i class="fas fa-crosshairs mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">The alignment problem: ensuring AI goals match human values</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-eye mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Interpretability: understanding how AI systems make decisions</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-exclamation-triangle mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Goal misalignment and unintended optimization</span>
                </div>
              </div>

              <a href="https://aisafety.info/questions/NM3J/5%3A%20AI%20may%20pursue%20goals" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-purple-700 hover:text-purple-500 transition-colors">
                <span class="underline">Learn more about AI goal pursuit</span>
                <i class="fas fa-external-link-alt ml-2" aria-hidden="true"></i>
              </a>
            </div>
          </div>

          <div class="timeline-item">
            <div class="info-card p-8">
              <h4 class="text-2xl font-bold mb-4" style="color: var(--color-lavender)">3. Consequences could be catastrophic, including human extinction.</h4>
              <p class="text-slate-600 leading-relaxed mb-6">
                AI may defeat us and take over, leading to humanity's extinction or permanent ruin. If we avoid this outcome, AI still has huge implications for the world, including great benefits if it's developed safely.
              </p>

              <div class="space-y-3 mb-4">
                <div class="flex items-center">
                  <i class="fas fa-skull-crossbones mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Catastrophic risk to humanity</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-globe mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Potential for irreversible global consequences</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-balance-scale mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">High stakes: enormous benefits if done right, catastrophe if done wrong</span>
                </div>
              </div>

              <a href="https://aisafety.info/questions/NM3O/8%3A%20AI%20can%20win%20a%20conflict%20against%20us" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-purple-700 hover:text-purple-500 transition-colors">
                <span class="underline">Learn more about AI conflict scenarios</span>
                <i class="fas fa-external-link-alt ml-2" aria-hidden="true"></i>
              </a>
            </div>
          </div>

          <div class="timeline-item">
            <div class="info-card p-8">
              <h4 class="text-2xl font-bold mb-4" style="color: var(--color-deep-purple)">4. We need to get our act together.</h4>
              <p class="text-slate-600 leading-relaxed mb-6">
                Experts are worried, but humanity doesn't have a real plan to avert disaster, and you may be able to help.
              </p>

              <div class="space-y-3 mb-4">
                <div class="flex items-center">
                  <i class="fas fa-university mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">AI governance: developing policies and regulations</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-users mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">International coordination and cooperation</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-brain mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Technical research and safety solutions</span>
                </div>
                <div class="flex items-center">
                  <i class="fas fa-hand-paper mr-3" aria-hidden="true"></i>
                  <span class="text-slate-600">Individual action and community building</span>
                </div>
              </div>

              <div class="space-y-2">
                <a href="https://aisafety.info/questions/NM3D/12%3A%20Experts%20are%20highly%20concerned" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-purple-700 hover:text-purple-500 transition-colors">
                  <span class="underline">Learn more about expert concerns</span>
                  <i class="fas fa-external-link-alt ml-2" aria-hidden="true"></i>
                </a>
                <br />
                <a href="https://www.aisafety.com/map" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-purple-700 hover:text-purple-500 transition-colors">
                  <span class="underline">Map of AI Safety Landscape</span>
                  <i class="fas fa-external-link-alt ml-2" aria-hidden="true"></i>
                </a>
              </div>
            </div>
          </div>
        </div>
      </div>

      {/* Links for Getting Started */}
      <div class="text-center mb-16">
        <h3 class="text-3xl md:text-4xl font-bold mb-6">Links for Getting Started</h3>
        <div class="section-divider"></div>
      </div>

      <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8 max-w-6xl mx-auto mb-12">
        <div class="info-card p-6 text-center">
          <div class="w-16 h-16 bg-gradient-to-br from-teal to-emerald rounded-xl flex items-center justify-center mx-auto mb-4">
            <i class="fas fa-book text-2xl text-white" aria-hidden="true"></i>
          </div>
          <h4 class="text-lg font-bold mb-4">Reading &amp; Watching</h4>
          <ul class="text-sm space-y-2 text-left">
            <li>• <a href="https://www.youtube.com/watch?v=pYXy-A4siMw" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Intro to AI Safety (18m video)
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://aisafety.info/questions/NM3T" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              The Case for AI Safety (article)
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.youtube.com/watch?v=LPZh9BOjkQs" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Intro to LLMs (7m video)
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.aisafety.com/" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              &amp; more
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
          </ul>
        </div>

        <div class="info-card p-6 text-center">
          <div class="w-16 h-16 bg-gradient-to-br from-emerald to-sage rounded-xl flex items-center justify-center mx-auto mb-4">
            <i class="fas fa-laptop-code text-2xl text-white" aria-hidden="true"></i>
          </div>
          <h4 class="text-lg font-bold mb-4">Upskilling</h4>
          <ul class="text-sm space-y-2 text-left">
            <li>• <a href="https://www.aisafety.com/events-and-training" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Events and Training
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.aisafety.com/courses" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Courses
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.aisafety.com/projects" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Projects
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
          </ul>
        </div>

        <div class="info-card p-6 text-center">
          <div class="w-16 h-16 bg-gradient-to-br from-ocean-blue to-warm-blue rounded-xl flex items-center justify-center mx-auto mb-4">
            <i class="fas fa-newspaper text-2xl text-white" aria-hidden="true"></i>
          </div>
          <h4 class="text-lg font-bold mb-4">In the News</h4>
          <ul class="text-sm space-y-2 text-left">
            <li>• <a href="https://www.theverge.com/2023/5/30/23742005/ai-risk-warning-22-word-statement-google-deepmind-openai" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Top AI researchers warn of extinction risk
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.transformernews.ai/p/ai-psychosis-stories-roundup" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              AI psychosis stories roundup
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.technologyreview.com/2023/05/02/1072528/geoffrey-hinton-google-why-scared-ai/" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Geoffrey Hinton on why he's scared of AI
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
            <li>• <a href="https://www.aisafety.com/stay-informed" target="_blank" rel="noopener noreferrer" class="text-purple-700 hover:text-purple-500 transition-colors underline decoration-purple-700/50 hover:decoration-purple-500 inline-flex items-center">
              Stay informed
              <i class="fas fa-external-link-alt ml-1 text-xs" aria-hidden="true"></i>
            </a></li>
          </ul>
        </div>
      </div>

      <div class="text-center">
        <p class="text-xl mb-6 leading-relaxed">
          Ready to dive deeper into AI safety? Join our community and start making a difference.
        </p>
        <a href="/get-involved/" class="inline-block px-12 py-4 bg-gradient-to-r from-bright-purple to-light-purple text-white font-bold text-lg rounded-full transition-colors duration-300 pulse-glow">
          Get Involved
        </a>
      </div>
    </div>
  </section>
</Layout>
